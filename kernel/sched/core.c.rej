--- kernel/sched/core.c
+++ kernel/sched/core.c
@@ -3233,18 +3096,23 @@ static struct rq *finish_task_switch(struct task_struct *prev)
 	 *   provided by mmdrop(),
 	 * - a sync_core for SYNC_CORE.
 	 */
-	/*
-	 * We use mmdrop_delayed() here so we don't have to do the
-	 * full __mmdrop() when we are the last user.
-	 */
 	if (mm) {
 		membarrier_mm_sync_core_before_usermode(mm);
-		mmdrop_delayed(mm);
+		mmdrop(mm);
 	}
 	if (unlikely(prev_state == TASK_DEAD)) {
 		if (prev->sched_class->task_dead)
 			prev->sched_class->task_dead(prev);
 
+		/*
+		 * Remove function-return probe instances associated with this
+		 * task and put them back on the free list.
+		 */
+		kprobe_flush_task(prev);
+
+		/* Task is done with its stack. */
+		put_task_stack(prev);
+
 		put_task_struct_rcu_user(prev);
 	}
 
@@ -7954,172 +7775,3 @@ const u32 sched_prio_to_wmult[40] = {
 };
 
 #undef CREATE_TRACE_POINTS
-
-#if defined(CONFIG_SMP) && defined(CONFIG_PREEMPT_RT)
-
-static inline void
-update_nr_migratory(struct task_struct *p, long delta)
-{
-	if (unlikely((p->sched_class == &rt_sched_class ||
-		      p->sched_class == &dl_sched_class) &&
-		      p->nr_cpus_allowed > 1)) {
-		if (p->sched_class == &rt_sched_class)
-			task_rq(p)->rt.rt_nr_migratory += delta;
-		else
-			task_rq(p)->dl.dl_nr_migratory += delta;
-	}
-}
-
-static inline void
-migrate_disable_update_cpus_allowed(struct task_struct *p)
-{
-	p->cpus_ptr = cpumask_of(smp_processor_id());
-	update_nr_migratory(p, -1);
-	p->nr_cpus_allowed = 1;
-}
-
-static inline void
-migrate_enable_update_cpus_allowed(struct task_struct *p)
-{
-	struct rq *rq;
-	struct rq_flags rf;
-
-	rq = task_rq_lock(p, &rf);
-	p->cpus_ptr = &p->cpus_mask;
-	p->nr_cpus_allowed = cpumask_weight(&p->cpus_mask);
-	update_nr_migratory(p, 1);
-	task_rq_unlock(rq, p, &rf);
-}
-
-void migrate_disable(void)
-{
-	preempt_disable();
-
-	if (++current->migrate_disable == 1) {
-		this_rq()->nr_pinned++;
-		preempt_lazy_disable();
-#ifdef CONFIG_SCHED_DEBUG
-		WARN_ON_ONCE(current->pinned_on_cpu >= 0);
-		current->pinned_on_cpu = smp_processor_id();
-#endif
-	}
-
-	preempt_enable();
-}
-EXPORT_SYMBOL(migrate_disable);
-
-static void migrate_disabled_sched(struct task_struct *p)
-{
-	if (p->migrate_disable_scheduled)
-		return;
-
-	migrate_disable_update_cpus_allowed(p);
-	p->migrate_disable_scheduled = 1;
-}
-
-static DEFINE_PER_CPU(struct cpu_stop_work, migrate_work);
-static DEFINE_PER_CPU(struct migration_arg, migrate_arg);
-
-void migrate_enable(void)
-{
-	struct task_struct *p = current;
-	struct rq *rq = this_rq();
-	int cpu = task_cpu(p);
-
-	WARN_ON_ONCE(p->migrate_disable <= 0);
-	if (p->migrate_disable > 1) {
-		p->migrate_disable--;
-		return;
-	}
-
-	preempt_disable();
-
-#ifdef CONFIG_SCHED_DEBUG
-	WARN_ON_ONCE(current->pinned_on_cpu != cpu);
-	current->pinned_on_cpu = -1;
-#endif
-
-	WARN_ON_ONCE(rq->nr_pinned < 1);
-
-	p->migrate_disable = 0;
-	rq->nr_pinned--;
-#ifdef CONFIG_HOTPLUG_CPU
-	if (rq->nr_pinned == 0 && unlikely(!cpu_active(cpu)) &&
-	    takedown_cpu_task)
-		wake_up_process(takedown_cpu_task);
-#endif
-
-	if (!p->migrate_disable_scheduled)
-		goto out;
-
-	p->migrate_disable_scheduled = 0;
-
-	migrate_enable_update_cpus_allowed(p);
-
-	WARN_ON(smp_processor_id() != cpu);
-	if (!is_cpu_allowed(p, cpu)) {
-		struct migration_arg __percpu *arg;
-		struct cpu_stop_work __percpu *work;
-		struct rq_flags rf;
-
-		work = this_cpu_ptr(&migrate_work);
-		arg = this_cpu_ptr(&migrate_arg);
-		WARN_ON_ONCE(!arg->done && !work->disabled && work->arg);
-
-		arg->task = p;
-		arg->done = false;
-
-		rq = task_rq_lock(p, &rf);
-		update_rq_clock(rq);
-		arg->dest_cpu = select_fallback_rq(cpu, p);
-		task_rq_unlock(rq, p, &rf);
-
-		stop_one_cpu_nowait(task_cpu(p), migration_cpu_stop,
-				    arg, work);
-	}
-
-out:
-	preempt_lazy_enable();
-	preempt_enable();
-}
-EXPORT_SYMBOL(migrate_enable);
-
-int cpu_nr_pinned(int cpu)
-{
-	struct rq *rq = cpu_rq(cpu);
-
-	return rq->nr_pinned;
-}
-
-#elif !defined(CONFIG_SMP) && defined(CONFIG_PREEMPT_RT)
-static void migrate_disabled_sched(struct task_struct *p)
-{
-}
-
-void migrate_disable(void)
-{
-#ifdef CONFIG_SCHED_DEBUG
-	current->migrate_disable++;
-#endif
-	barrier();
-}
-EXPORT_SYMBOL(migrate_disable);
-
-void migrate_enable(void)
-{
-#ifdef CONFIG_SCHED_DEBUG
-	struct task_struct *p = current;
-
-	WARN_ON_ONCE(p->migrate_disable <= 0);
-	p->migrate_disable--;
-#endif
-	barrier();
-}
-EXPORT_SYMBOL(migrate_enable);
-
-#else
-static void migrate_disabled_sched(struct task_struct *p)
-{
-}
-
-#endif
